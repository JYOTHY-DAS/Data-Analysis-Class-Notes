# Day3:Historical development of AI: Presented by Mr. Sajil CK
### First Mr.Sajil CK introduced us to a machine developed by Germany in WW II for data encryption named as Enigma- II. Mr.Sajil said that modern computing started from the attempts to decrypt these messages. Mr. Allen Turing was key figure in braking these encrypted messages and now he is known as the father of modern computer.
### Then we discussed about the concept of neural networks. He said that the idea of neural networks originated from the concept of neural pathway development in humans. Neuroplasticity is the adapting/learning ability of brain which we can use in training neural networks.
### In 1958 Frank Rosenblatt developed the Perceptron which is a simple model of biological neuron. We can say that it is a single layer neural network algorithm.
### 'Perceptrons: An Introduction to Computational Geometry' is a book written by Marvin Minsky and Seymour Papert and published in 1969. The crux of this book is a number of mathematical proofs which acknowledge some of the perceptron's strengths while also showing major limitations. The most important one is related to the computation of some predicates, such as the XOR function, and also the important connectedness predicate. After the publication of this book researchers started to question  the ability of 'Perceptron' to learn. 
### XOR, or exclusive-OR, is a logical operator that compares two or more inputs and produces a single output. The output is true if the number of true inputs is odd, and false if it is even. 
### If it cannot learn basic functions like XOR how can it learn day to day activities like walk, talk etc.
|a|b|y|
| :---:| :---: | :---: |
| 0  | 0   | 0   |
| 0  |   1 | 1   |
| 1  |  0  | 1   |
| 1  |  1  | 1   |
